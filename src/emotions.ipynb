{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "data = pd.read_csv('../data/training.1600000.processed.noemoticon.csv', encoding='latin-1')\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data = data.sample(20000, random_state=42)\n",
    "\n",
    "data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predprocesiranje teksta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "data['target'] = data['target'].replace(4, 1)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data['text'], data['target'], test_size=0.2, random_state=42)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jedinstvene oznake u celom skupu podataka: [0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_targets_full = data['target'].unique()\n",
    "print(f'Jedinstvene oznake u celom skupu podataka: {unique_targets_full}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_encodings, train_labels.tolist())\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c7990e11b3463ebf84239d2f12d2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3286, 'grad_norm': 15.167470932006836, 'learning_rate': 1.3545454545454547e-05, 'epoch': 2.25}\n",
      "{'loss': 0.3741, 'grad_norm': 0.8420503735542297, 'learning_rate': 1.3454545454545457e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1901, 'grad_norm': 29.57876968383789, 'learning_rate': 1.3363636363636364e-05, 'epoch': 2.27}\n",
      "{'loss': 0.3552, 'grad_norm': 6.342377185821533, 'learning_rate': 1.3272727272727273e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2001, 'grad_norm': 0.4319951832294464, 'learning_rate': 1.318181818181818e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2636, 'grad_norm': 0.41427087783813477, 'learning_rate': 1.3090909090909093e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2241, 'grad_norm': 4.239613056182861, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.29}\n",
      "{'loss': 0.358, 'grad_norm': 0.40873804688453674, 'learning_rate': 1.290909090909091e-05, 'epoch': 2.29}\n",
      "{'loss': 0.2144, 'grad_norm': 0.32359832525253296, 'learning_rate': 1.2818181818181818e-05, 'epoch': 2.29}\n",
      "{'loss': 0.4775, 'grad_norm': 31.846782684326172, 'learning_rate': 1.2727272727272727e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2321, 'grad_norm': 4.912447452545166, 'learning_rate': 1.2636363636363638e-05, 'epoch': 2.31}\n",
      "{'loss': 0.2815, 'grad_norm': 5.681141376495361, 'learning_rate': 1.2545454545454547e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1777, 'grad_norm': 0.272242933511734, 'learning_rate': 1.2454545454545454e-05, 'epoch': 2.31}\n",
      "{'loss': 0.4576, 'grad_norm': 0.3159676194190979, 'learning_rate': 1.2363636363636365e-05, 'epoch': 2.32}\n",
      "{'loss': 0.2881, 'grad_norm': 70.31010437011719, 'learning_rate': 1.2272727272727273e-05, 'epoch': 2.33}\n",
      "{'loss': 0.3037, 'grad_norm': 7.550289630889893, 'learning_rate': 1.2181818181818182e-05, 'epoch': 2.33}\n",
      "{'loss': 0.2636, 'grad_norm': 24.85054588317871, 'learning_rate': 1.2090909090909091e-05, 'epoch': 2.33}\n",
      "{'loss': 0.4587, 'grad_norm': 0.45115816593170166, 'learning_rate': 1.2e-05, 'epoch': 2.34}\n",
      "{'loss': 0.3232, 'grad_norm': 9.952592849731445, 'learning_rate': 1.190909090909091e-05, 'epoch': 2.34}\n",
      "{'loss': 0.2615, 'grad_norm': 0.5197121500968933, 'learning_rate': 1.1818181818181819e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3582, 'grad_norm': 4.126097679138184, 'learning_rate': 1.1727272727272728e-05, 'epoch': 2.35}\n",
      "{'loss': 0.2955, 'grad_norm': 7.754199028015137, 'learning_rate': 1.1636363636363637e-05, 'epoch': 2.36}\n",
      "{'loss': 0.3051, 'grad_norm': 5.040560722351074, 'learning_rate': 1.1545454545454545e-05, 'epoch': 2.37}\n",
      "{'loss': 0.3021, 'grad_norm': 0.7350075840950012, 'learning_rate': 1.1454545454545455e-05, 'epoch': 2.37}\n",
      "{'loss': 0.1259, 'grad_norm': 0.6038039326667786, 'learning_rate': 1.1363636363636365e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2341, 'grad_norm': 8.371664047241211, 'learning_rate': 1.1272727272727274e-05, 'epoch': 2.38}\n",
      "{'loss': 0.5073, 'grad_norm': 5.168224334716797, 'learning_rate': 1.1181818181818183e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2681, 'grad_norm': 0.42938917875289917, 'learning_rate': 1.1090909090909092e-05, 'epoch': 2.39}\n",
      "{'loss': 0.2701, 'grad_norm': 0.22504973411560059, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.4}\n",
      "{'loss': 0.3533, 'grad_norm': 28.33364486694336, 'learning_rate': 1.0909090909090909e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2893, 'grad_norm': 25.378366470336914, 'learning_rate': 1.081818181818182e-05, 'epoch': 2.41}\n",
      "{'loss': 0.2378, 'grad_norm': 1.7138299942016602, 'learning_rate': 1.0727272727272727e-05, 'epoch': 2.41}\n",
      "{'loss': 0.2803, 'grad_norm': 0.586115300655365, 'learning_rate': 1.0636363636363638e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1733, 'grad_norm': 8.362959861755371, 'learning_rate': 1.0545454545454546e-05, 'epoch': 2.42}\n",
      "{'loss': 0.287, 'grad_norm': 4.5723114013671875, 'learning_rate': 1.0454545454545455e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1862, 'grad_norm': 4.707111358642578, 'learning_rate': 1.0363636363636364e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2788, 'grad_norm': 0.41812729835510254, 'learning_rate': 1.0272727272727273e-05, 'epoch': 2.44}\n",
      "{'loss': 0.2208, 'grad_norm': 12.95627212524414, 'learning_rate': 1.0181818181818182e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0111, 'grad_norm': 0.2972700595855713, 'learning_rate': 1.0090909090909092e-05, 'epoch': 2.44}\n",
      "{'loss': 0.3292, 'grad_norm': 26.93282127380371, 'learning_rate': 1e-05, 'epoch': 2.45}\n",
      "{'loss': 0.3688, 'grad_norm': 0.18841229379177094, 'learning_rate': 9.90909090909091e-06, 'epoch': 2.46}\n",
      "{'loss': 0.2109, 'grad_norm': 0.47901642322540283, 'learning_rate': 9.818181818181818e-06, 'epoch': 2.46}\n",
      "{'loss': 0.1916, 'grad_norm': 22.464828491210938, 'learning_rate': 9.727272727272728e-06, 'epoch': 2.46}\n",
      "{'loss': 0.3412, 'grad_norm': 91.72252655029297, 'learning_rate': 9.636363636363636e-06, 'epoch': 2.47}\n",
      "{'loss': 0.3847, 'grad_norm': 6.499448776245117, 'learning_rate': 9.545454545454547e-06, 'epoch': 2.48}\n",
      "{'loss': 0.1944, 'grad_norm': 3.5255284309387207, 'learning_rate': 9.454545454545454e-06, 'epoch': 2.48}\n",
      "{'loss': 0.2367, 'grad_norm': 0.14978279173374176, 'learning_rate': 9.363636363636365e-06, 'epoch': 2.48}\n",
      "{'loss': 0.3356, 'grad_norm': 0.1785813570022583, 'learning_rate': 9.272727272727273e-06, 'epoch': 2.49}\n",
      "{'loss': 0.1064, 'grad_norm': 30.69220733642578, 'learning_rate': 9.181818181818182e-06, 'epoch': 2.5}\n",
      "{'loss': 0.3562, 'grad_norm': 4.262908935546875, 'learning_rate': 9.090909090909091e-06, 'epoch': 2.5}\n",
      "{'loss': 0.2277, 'grad_norm': 0.3041042983531952, 'learning_rate': 9e-06, 'epoch': 2.5}\n",
      "{'loss': 0.385, 'grad_norm': 22.268009185791016, 'learning_rate': 8.90909090909091e-06, 'epoch': 2.51}\n",
      "{'loss': 0.5299, 'grad_norm': 66.03763580322266, 'learning_rate': 8.818181818181819e-06, 'epoch': 2.52}\n",
      "{'loss': 0.345, 'grad_norm': 9.04017448425293, 'learning_rate': 8.727272727272728e-06, 'epoch': 2.52}\n",
      "{'loss': 0.4599, 'grad_norm': 27.180078506469727, 'learning_rate': 8.636363636363637e-06, 'epoch': 2.52}\n",
      "{'loss': 0.4873, 'grad_norm': 34.2223014831543, 'learning_rate': 8.545454545454546e-06, 'epoch': 2.53}\n",
      "{'loss': 0.282, 'grad_norm': 18.097280502319336, 'learning_rate': 8.454545454545455e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1817, 'grad_norm': 4.5082478523254395, 'learning_rate': 8.363636363636365e-06, 'epoch': 2.54}\n",
      "{'loss': 0.3448, 'grad_norm': 17.663854598999023, 'learning_rate': 8.272727272727274e-06, 'epoch': 2.54}\n",
      "{'loss': 0.3315, 'grad_norm': 4.143237113952637, 'learning_rate': 8.181818181818183e-06, 'epoch': 2.55}\n",
      "{'loss': 0.2981, 'grad_norm': 5.990045070648193, 'learning_rate': 8.09090909090909e-06, 'epoch': 2.56}\n",
      "{'loss': 0.2314, 'grad_norm': 18.731483459472656, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0786, 'grad_norm': 0.22708876430988312, 'learning_rate': 7.909090909090909e-06, 'epoch': 2.56}\n",
      "{'loss': 0.1113, 'grad_norm': 44.53946304321289, 'learning_rate': 7.81818181818182e-06, 'epoch': 2.57}\n",
      "{'loss': 0.4105, 'grad_norm': 56.059349060058594, 'learning_rate': 7.727272727272727e-06, 'epoch': 2.58}\n",
      "{'loss': 0.2573, 'grad_norm': 0.20793943107128143, 'learning_rate': 7.636363636363638e-06, 'epoch': 2.58}\n",
      "{'loss': 0.4299, 'grad_norm': 29.06601905822754, 'learning_rate': 7.545454545454546e-06, 'epoch': 2.58}\n",
      "{'loss': 0.3647, 'grad_norm': 0.2983796298503876, 'learning_rate': 7.454545454545454e-06, 'epoch': 2.59}\n",
      "{'loss': 0.242, 'grad_norm': 1.2599455118179321, 'learning_rate': 7.363636363636364e-06, 'epoch': 2.59}\n",
      "{'loss': 0.2404, 'grad_norm': 55.17795181274414, 'learning_rate': 7.272727272727272e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3944, 'grad_norm': 23.287456512451172, 'learning_rate': 7.181818181818182e-06, 'epoch': 2.6}\n",
      "{'loss': 0.4213, 'grad_norm': 21.898113250732422, 'learning_rate': 7.090909090909091e-06, 'epoch': 2.61}\n",
      "{'loss': 0.2426, 'grad_norm': 1.7987686395645142, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2337, 'grad_norm': 2.422700881958008, 'learning_rate': 6.909090909090909e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1526, 'grad_norm': 0.13965147733688354, 'learning_rate': 6.818181818181818e-06, 'epoch': 2.62}\n",
      "{'loss': 0.317, 'grad_norm': 11.213354110717773, 'learning_rate': 6.727272727272728e-06, 'epoch': 2.63}\n",
      "{'loss': 0.2554, 'grad_norm': 8.9564790725708, 'learning_rate': 6.636363636363637e-06, 'epoch': 2.63}\n",
      "{'loss': 0.2393, 'grad_norm': 62.12610626220703, 'learning_rate': 6.545454545454547e-06, 'epoch': 2.64}\n",
      "{'loss': 0.2391, 'grad_norm': 9.596823692321777, 'learning_rate': 6.454545454545455e-06, 'epoch': 2.65}\n",
      "{'loss': 0.2713, 'grad_norm': 4.214555263519287, 'learning_rate': 6.363636363636363e-06, 'epoch': 2.65}\n",
      "{'loss': 0.353, 'grad_norm': 16.437347412109375, 'learning_rate': 6.2727272727272734e-06, 'epoch': 2.66}\n",
      "{'loss': 0.4698, 'grad_norm': 16.067060470581055, 'learning_rate': 6.181818181818183e-06, 'epoch': 2.66}\n",
      "{'loss': 0.1151, 'grad_norm': 1.1235921382904053, 'learning_rate': 6.090909090909091e-06, 'epoch': 2.67}\n",
      "{'loss': 0.1738, 'grad_norm': 7.4611687660217285, 'learning_rate': 6e-06, 'epoch': 2.67}\n",
      "{'loss': 0.3039, 'grad_norm': 36.76388168334961, 'learning_rate': 5.909090909090909e-06, 'epoch': 2.67}\n",
      "{'loss': 0.2118, 'grad_norm': 9.73946762084961, 'learning_rate': 5.8181818181818185e-06, 'epoch': 2.68}\n",
      "{'loss': 0.1265, 'grad_norm': 34.38148498535156, 'learning_rate': 5.727272727272728e-06, 'epoch': 2.69}\n",
      "{'loss': 0.2225, 'grad_norm': 0.2245643585920334, 'learning_rate': 5.636363636363637e-06, 'epoch': 2.69}\n",
      "{'loss': 0.1679, 'grad_norm': 0.35685500502586365, 'learning_rate': 5.545454545454546e-06, 'epoch': 2.69}\n",
      "{'loss': 0.1809, 'grad_norm': 0.18950346112251282, 'learning_rate': 5.4545454545454545e-06, 'epoch': 2.7}\n",
      "{'loss': 0.2478, 'grad_norm': 19.234302520751953, 'learning_rate': 5.363636363636364e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1343, 'grad_norm': 25.74410057067871, 'learning_rate': 5.272727272727273e-06, 'epoch': 2.71}\n",
      "{'loss': 0.6053, 'grad_norm': 45.352745056152344, 'learning_rate': 5.181818181818182e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2208, 'grad_norm': 7.948046684265137, 'learning_rate': 5.090909090909091e-06, 'epoch': 2.72}\n",
      "{'loss': 0.4112, 'grad_norm': 16.604890823364258, 'learning_rate': 5e-06, 'epoch': 2.73}\n",
      "{'loss': 0.1923, 'grad_norm': 0.2343076914548874, 'learning_rate': 4.909090909090909e-06, 'epoch': 2.73}\n",
      "{'loss': 0.0736, 'grad_norm': 10.054818153381348, 'learning_rate': 4.818181818181818e-06, 'epoch': 2.73}\n",
      "{'loss': 0.2894, 'grad_norm': 30.091846466064453, 'learning_rate': 4.727272727272727e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1553, 'grad_norm': 21.538875579833984, 'learning_rate': 4.636363636363636e-06, 'epoch': 2.75}\n",
      "{'loss': 0.2097, 'grad_norm': 8.644103050231934, 'learning_rate': 4.5454545454545455e-06, 'epoch': 2.75}\n",
      "{'loss': 0.3007, 'grad_norm': 0.3033525347709656, 'learning_rate': 4.454545454545455e-06, 'epoch': 2.75}\n",
      "{'loss': 0.2339, 'grad_norm': 14.173836708068848, 'learning_rate': 4.363636363636364e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2228, 'grad_norm': 0.5981384515762329, 'learning_rate': 4.272727272727273e-06, 'epoch': 2.77}\n",
      "{'loss': 0.3506, 'grad_norm': 5.36997127532959, 'learning_rate': 4.181818181818182e-06, 'epoch': 2.77}\n",
      "{'loss': 0.3936, 'grad_norm': 16.039026260375977, 'learning_rate': 4.0909090909090915e-06, 'epoch': 2.77}\n",
      "{'loss': 0.3537, 'grad_norm': 7.692497730255127, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1379, 'grad_norm': 12.549428939819336, 'learning_rate': 3.90909090909091e-06, 'epoch': 2.79}\n",
      "{'loss': 0.2645, 'grad_norm': 21.459970474243164, 'learning_rate': 3.818181818181819e-06, 'epoch': 2.79}\n",
      "{'loss': 0.2138, 'grad_norm': 49.06501007080078, 'learning_rate': 3.727272727272727e-06, 'epoch': 2.79}\n",
      "{'loss': 0.3933, 'grad_norm': 52.86311721801758, 'learning_rate': 3.636363636363636e-06, 'epoch': 2.8}\n",
      "{'loss': 0.3135, 'grad_norm': 37.6177864074707, 'learning_rate': 3.5454545454545454e-06, 'epoch': 2.81}\n",
      "{'loss': 0.5354, 'grad_norm': 5.555147647857666, 'learning_rate': 3.4545454545454545e-06, 'epoch': 2.81}\n",
      "{'loss': 0.3122, 'grad_norm': 29.420669555664062, 'learning_rate': 3.363636363636364e-06, 'epoch': 2.81}\n",
      "{'loss': 0.3058, 'grad_norm': 7.65900993347168, 'learning_rate': 3.2727272727272733e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0895, 'grad_norm': 5.9568190574646, 'learning_rate': 3.1818181818181817e-06, 'epoch': 2.83}\n",
      "{'loss': 0.3282, 'grad_norm': 29.717100143432617, 'learning_rate': 3.0909090909090913e-06, 'epoch': 2.83}\n",
      "{'loss': 0.1373, 'grad_norm': 0.8618040084838867, 'learning_rate': 3e-06, 'epoch': 2.83}\n",
      "{'loss': 0.3753, 'grad_norm': 0.33523330092430115, 'learning_rate': 2.9090909090909093e-06, 'epoch': 2.84}\n",
      "{'loss': 0.2967, 'grad_norm': 5.884259223937988, 'learning_rate': 2.8181818181818185e-06, 'epoch': 2.84}\n",
      "{'loss': 0.3207, 'grad_norm': 44.20978546142578, 'learning_rate': 2.7272727272727272e-06, 'epoch': 2.85}\n",
      "{'loss': 0.121, 'grad_norm': 0.1653607040643692, 'learning_rate': 2.6363636363636364e-06, 'epoch': 2.85}\n",
      "{'loss': 0.4378, 'grad_norm': 0.19345813989639282, 'learning_rate': 2.5454545454545456e-06, 'epoch': 2.86}\n",
      "{'loss': 0.306, 'grad_norm': 34.433319091796875, 'learning_rate': 2.4545454545454544e-06, 'epoch': 2.87}\n",
      "{'loss': 0.2675, 'grad_norm': 15.688631057739258, 'learning_rate': 2.3636363636363636e-06, 'epoch': 2.87}\n",
      "{'loss': 0.3257, 'grad_norm': 1.5053075551986694, 'learning_rate': 2.2727272727272728e-06, 'epoch': 2.88}\n",
      "{'loss': 0.2455, 'grad_norm': 121.67034149169922, 'learning_rate': 2.181818181818182e-06, 'epoch': 2.88}\n",
      "{'loss': 0.203, 'grad_norm': 15.362584114074707, 'learning_rate': 2.090909090909091e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1726, 'grad_norm': 0.839916467666626, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.89}\n",
      "{'loss': 0.1889, 'grad_norm': 0.47955942153930664, 'learning_rate': 1.9090909090909095e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1124, 'grad_norm': 0.39866432547569275, 'learning_rate': 1.818181818181818e-06, 'epoch': 2.9}\n",
      "{'loss': 0.2724, 'grad_norm': 4.8823137283325195, 'learning_rate': 1.7272727272727273e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2895, 'grad_norm': 7.016351222991943, 'learning_rate': 1.6363636363636367e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2774, 'grad_norm': 112.68740844726562, 'learning_rate': 1.5454545454545457e-06, 'epoch': 2.92}\n",
      "{'loss': 0.3356, 'grad_norm': 21.822763442993164, 'learning_rate': 1.4545454545454546e-06, 'epoch': 2.92}\n",
      "{'loss': 0.297, 'grad_norm': 69.71479034423828, 'learning_rate': 1.3636363636363636e-06, 'epoch': 2.92}\n",
      "{'loss': 0.2379, 'grad_norm': 0.8444115519523621, 'learning_rate': 1.2727272727272728e-06, 'epoch': 2.93}\n",
      "{'loss': 0.2128, 'grad_norm': 3.287045955657959, 'learning_rate': 1.1818181818181818e-06, 'epoch': 2.94}\n",
      "{'loss': 0.1339, 'grad_norm': 22.93638038635254, 'learning_rate': 1.090909090909091e-06, 'epoch': 2.94}\n",
      "{'loss': 0.3666, 'grad_norm': 14.794574737548828, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.94}\n",
      "{'loss': 0.2169, 'grad_norm': 47.79647445678711, 'learning_rate': 9.09090909090909e-07, 'epoch': 2.95}\n",
      "{'loss': 0.3821, 'grad_norm': 18.150020599365234, 'learning_rate': 8.181818181818183e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1744, 'grad_norm': 18.93691635131836, 'learning_rate': 7.272727272727273e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1769, 'grad_norm': 0.280416339635849, 'learning_rate': 6.363636363636364e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1762, 'grad_norm': 38.24479293823242, 'learning_rate': 5.454545454545455e-07, 'epoch': 2.97}\n",
      "{'loss': 0.1963, 'grad_norm': 0.3130592405796051, 'learning_rate': 4.545454545454545e-07, 'epoch': 2.98}\n",
      "{'loss': 0.329, 'grad_norm': 8.200627326965332, 'learning_rate': 3.6363636363636366e-07, 'epoch': 2.98}\n",
      "{'loss': 0.3714, 'grad_norm': 6.603333473205566, 'learning_rate': 2.7272727272727274e-07, 'epoch': 2.98}\n",
      "{'loss': 0.1809, 'grad_norm': 1.917020559310913, 'learning_rate': 1.8181818181818183e-07, 'epoch': 2.99}\n",
      "{'loss': 0.4412, 'grad_norm': 5.337615013122559, 'learning_rate': 9.090909090909091e-08, 'epoch': 3.0}\n",
      "{'loss': 0.3649, 'grad_norm': 1.9069010019302368, 'learning_rate': 0.0, 'epoch': 3.0}\n",
      "{'train_runtime': 24184.1941, 'train_samples_per_second': 1.985, 'train_steps_per_second': 0.248, 'train_loss': 0.0693953210785985, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=0.0693953210785985, metrics={'train_runtime': 24184.1941, 'train_samples_per_second': 1.985, 'train_steps_per_second': 0.248, 'total_flos': 2614689588672000.0, 'train_loss': 0.0693953210785985, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint = './results/checkpoint-4500'\n",
    "\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b6734ac4b64002b045528e6aba1af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9529119729995728, 'eval_accuracy': 0.75475, 'eval_precision': 0.7558748992722419, 'eval_recall': 0.75475, 'eval_f1': 0.7543155648032276, 'eval_runtime': 4186.5257, 'eval_samples_per_second': 0.955, 'eval_steps_per_second': 0.119}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model\\\\tokenizer_config.json',\n",
       " './saved_model\\\\special_tokens_map.json',\n",
       " './saved_model\\\\vocab.txt',\n",
       " './saved_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sačuvajte model\n",
    "model.save_pretrained('./saved_model')\n",
    "# Sačuvajte tokenizer\n",
    "tokenizer.save_pretrained('./saved_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
